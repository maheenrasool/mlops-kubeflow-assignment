name: Preprocess data
inputs:
- {name: dataset_path, type: String}
- {name: output_dir, type: String}
implementation:
  container:
    image: python:3.8
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def preprocess_data(dataset_path, output_dir):
          os.makedirs(output_dir, exist_ok=True)
          df = pd.read_csv(dataset_path).dropna()

          X = df.drop("medv", axis=1)
          y = df["medv"]

          X_scaled = StandardScaler().fit_transform(X)

          X_train, X_test, y_train, y_test = train_test_split(
              X_scaled, y, test_size=0.2, random_state=42
          )

          joblib.dump(X_train, f"{output_dir}/X_train.pkl")
          joblib.dump(X_test, f"{output_dir}/X_test.pkl")
          joblib.dump(y_train, f"{output_dir}/y_train.pkl")
          joblib.dump(y_test, f"{output_dir}/y_test.pkl")

      import argparse
      _parser = argparse.ArgumentParser(prog='Preprocess data', description='')
      _parser.add_argument("--dataset-path", dest="dataset_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--output-dir", dest="output_dir", type=str, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = preprocess_data(**_parsed_args)
    args:
    - --dataset-path
    - {inputValue: dataset_path}
    - --output-dir
    - {inputValue: output_dir}
